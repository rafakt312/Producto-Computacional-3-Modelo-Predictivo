{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784899d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [markdown]\n",
    "# # Producto Computacional 3: Modelamiento Predictivo con Datos MHEALTH\n",
    "# \n",
    "# **Nombre:** <TU_NOMBRE_AQUÍ>\n",
    "# \n",
    "# ## Objetivo General\n",
    "# \n",
    "# Aplicar técnicas de Machine Learning para construir y validar modelos capaces de reconocer actividades humanas a partir de los sensores del dataset MHEALTH, evaluando su desempeño mediante métricas apropiadas.\n",
    "# \n",
    "# ## Modelos a Implementar\n",
    "# \n",
    "# 1.  **Random Forest Classifier:** Un modelo de ensamble robusto que no requiere escalado de datos.\n",
    "# 2.  **K-Nearest Neighbors (KNN):** Un modelo basado en distancia que sí requiere escalado de datos, permitiéndonos cumplir con ese requerimiento.\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 0. IMPORTACIÓN DE LIBRERÍAS\n",
    "# ------------------------------------------------\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configuraciones de visualización\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Librerías importadas exitosamente.\")\n",
    "\n",
    "#%% [markdown]\n",
    "# ## 1. Carga y Preprocesamiento de los Datos\n",
    "# \n",
    "# ### 1.1. Descarga y Descompresión de los Datos\n",
    "# \n",
    "# El dataset MHEALTH se descargará del repositorio UCI. Consiste en 10 archivos `.log` (uno por sujeto).\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 1.1. DESCARGA Y EXTRACCIÓN DE DATOS\n",
    "# ------------------------------------------------\n",
    "DATA_URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00319/MHEALTHDATASET.zip\"\n",
    "ZIP_PATH = \"MHEALTHDATASET.zip\"\n",
    "DATA_DIR = \"MHEALTHDATASET\"\n",
    "\n",
    "# Descargar el archivo si no existe\n",
    "if not os.path.exists(ZIP_PATH):\n",
    "    print(f\"Descargando {ZIP_PATH}...\")\n",
    "    urllib.request.urlretrieve(DATA_URL, ZIP_PATH)\n",
    "    print(\"Descarga completa.\")\n",
    "else:\n",
    "    print(f\"{ZIP_PATH} ya existe.\")\n",
    "\n",
    "# Descomprimir el archivo si el directorio no existe\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"Descomprimiendo {ZIP_PATH}...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\".\")\n",
    "    print(f\"Archivos extraídos en el directorio '{DATA_DIR}'.\")\n",
    "else:\n",
    "    print(f\"El directorio '{DATA_DIR}' ya existe.\")\n",
    "\n",
    "#%% [markdown]\n",
    "# ### 1.2. Carga y Consolidación de los Datos\n",
    "# \n",
    "# Se leerán los 10 archivos `.log` y se consolidarán en un único DataFrame de Pandas. Se definirán las columnas y las etiquetas de actividad según el `README.txt` del dataset.\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 1.2. DEFINICIÓN DE ESTRUCTURA Y CARGA\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Definir los nombres de las columnas (23 sensores + 1 etiqueta)\n",
    "column_names = [\n",
    "    'Chest_Accel_X', 'Chest_Accel_Y', 'Chest_Accel_Z',\n",
    "    'Chest_ECG_Lead1', 'Chest_ECG_Lead2',\n",
    "    'Ankle_Accel_X', 'Ankle_Accel_Y', 'Ankle_Accel_Z',\n",
    "    'Ankle_Gyro_X', 'Ankle_Gyro_Y', 'Ankle_Gyro_Z',\n",
    "    'Ankle_Mag_X', 'Ankle_Mag_Y', 'Ankle_Mag_Z',\n",
    "    'Arm_Accel_X', 'Arm_Accel_Y', 'Arm_Accel_Z',\n",
    "    'Arm_Gyro_X', 'Arm_Gyro_Y', 'Arm_Gyro_Z',\n",
    "    'Arm_Mag_X', 'Arm_Mag_Y', 'Arm_Mag_Z',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "# Definir las etiquetas de actividad (Label 0 es \"Null\" y debe ser descartado)\n",
    "activity_labels = {\n",
    "    1: 'Standing',\n",
    "    2: 'Sitting',\n",
    "    3: 'Lying',\n",
    "    4: 'Walking',\n",
    "    5: 'Climbing Stairs',\n",
    "    6: 'Waist Bends',\n",
    "    7: 'Arm Elevation',\n",
    "    8: 'Knees Bending',\n",
    "    9: 'Cycling',\n",
    "    10: 'Jogging',\n",
    "    11: 'Running',\n",
    "    12: 'Jump Front & Back'\n",
    "}\n",
    "\n",
    "def load_mhealth_data(data_dir, column_names):\n",
    "    \"\"\"Carga todos los archivos .log del directorio MHEALTH en un DataFrame.\"\"\"\n",
    "    log_files = glob.glob(os.path.join(data_dir, \"mHealth_subject*.log\"))\n",
    "    all_data = []\n",
    "    \n",
    "    for i, log_file in enumerate(log_files):\n",
    "        subject_id = i + 1\n",
    "        print(f\"Cargando archivo: {log_file} (Sujeto {subject_id})...\")\n",
    "        try:\n",
    "            df_subject = pd.read_csv(log_file, sep='\\s+', header=None, names=column_names)\n",
    "            df_subject['Subject'] = subject_id\n",
    "            all_data.append(df_subject)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cargando {log_file}: {e}\")\n",
    "            \n",
    "    if not all_data:\n",
    "        print(\"No se cargaron datos. Revisa la ruta y los archivos.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_combined = pd.concat(all_data, ignore_index=True)\n",
    "    return df_combined\n",
    "\n",
    "# Cargar y consolidar los datos\n",
    "df = load_mhealth_data(DATA_DIR, column_names)\n",
    "\n",
    "print(\"\\nDatos cargados y consolidados.\")\n",
    "print(f\"Dimensiones totales del DataFrame: {df.shape}\")\n",
    "df.head()\n",
    "\n",
    "#%% [markdown]\n",
    "# ### 1.3. Limpieza y Preparación de Datos (Requerimiento 1)\n",
    "# \n",
    "# 1.  **Limpieza:** Se eliminarán las filas con `Label == 0` (actividad Nula).\n",
    "# 2.  **Selección de Variables:** Se seleccionará un subconjunto de variables. Para este análisis, **excluiremos las señales de ECG** (`Chest_ECG_Lead1`, `Chest_ECG_Lead2`) para enfocarnos solo en los sensores inerciales (Acelerómetros, Giroscopios, Magnetómetros).\n",
    "# 3.  **División de Datos:** Se dividirán los datos en 70% (entrenamiento) y 30% (prueba), usando estratificación (`stratify=y`) para mantener la proporción de las clases.\n",
    "# 4.  **Estandarización:** Se aplicará `StandardScaler` (Normalización Z-score) a los datos, lo cual es esencial para el modelo KNN.\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 1.3. LIMPIEZA Y PREPARACIÓN\n",
    "# ------------------------------------------------\n",
    "\n",
    "# 1. Limpieza: Eliminar la clase 0 (Nula)\n",
    "df_clean = df[df['Label'] != 0].copy()\n",
    "print(f\"Forma original: {df.shape}, Forma sin clase Nula: {df_clean.shape}\")\n",
    "\n",
    "# Mapear nombres de actividades para visualización\n",
    "df_clean['Activity'] = df_clean['Label'].map(activity_labels)\n",
    "\n",
    "# 2. Selección de Variables (Features y Target)\n",
    "# Excluimos ECG, Label, Activity y Subject\n",
    "features = [col for col in df_clean.columns if col not in ['Chest_ECG_Lead1', 'Chest_ECG_Lead2', 'Label', 'Activity', 'Subject']]\n",
    "target = 'Label'\n",
    "\n",
    "print(f\"\\nVariables predictoras ({len(features)}): {features}\")\n",
    "print(f\"Variable objetivo: {target}\")\n",
    "\n",
    "# Definir X e y\n",
    "X = df_clean[features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# 3. División de Datos (70% Train / 30% Test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y  # Asegura la representatividad de las clases\n",
    ")\n",
    "\n",
    "print(f\"\\nForma de X_train: {X_train.shape}\")\n",
    "print(f\"Forma de X_test: {X_test.shape}\")\n",
    "print(f\"Distribución de clases en y_train:\\n{y_train.value_counts(normalize=True).sort_index()}\")\n",
    "\n",
    "# 4. Aplicar Estandarización\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el escalador SÓLO con los datos de entrenamiento\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Aplicar la transformación a los datos de entrenamiento y prueba\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nDatos estandarizados listos.\")\n",
    "\n",
    "#%% [markdown]\n",
    "# ## 2. Construcción de Modelo 1: Random Forest\n",
    "# \n",
    "# Se entrenará un `RandomForestClassifier`. Este modelo no es sensible a la escala de los datos, por lo que usaremos los datos **sin escalar** (`X_train`) para demostrarlo.\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 2.1. ENTRENAMIENTO RANDOM FOREST\n",
    "# ------------------------------------------------\n",
    "print(\"Entrenando Modelo 1: Random Forest...\")\n",
    "\n",
    "# n_jobs=-1 usa todos los procesadores disponibles\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Entrenar con datos NO escalados\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Entrenamiento de Random Forest completado.\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3.1. VALIDACIÓN RANDOM FOREST\n",
    "# ------------------------------------------------\n",
    "print(\"Evaluando Random Forest...\")\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Reporte de métricas\n",
    "print(\"\\n--- Reporte de Clasificación (Random Forest) ---\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=activity_labels.values()))\n",
    "\n",
    "# Guardar la matriz de confusión\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "#%% [markdown]\n",
    "# ### 4. Visualización (Random Forest)\n",
    "# \n",
    "# #### 4.1. Matriz de Confusión (Heatmap)\n",
    "# \n",
    "# Se define una función auxiliar para graficar la matriz de confusión.\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 4.1. FUNCIÓN AUXILIAR Y MATRIZ DE CONFUSIÓN (RF)\n",
    "# ------------------------------------------------\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title):\n",
    "    \"\"\"Grafica una matriz de confusión usando Seaborn.\"\"\"\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    # Normalizar la matriz por fila (recall)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=True, fmt=\".2f\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.ylabel('Etiqueta Verdadera')\n",
    "    plt.xlabel('Etiqueta Predicha')\n",
    "    plt.show()\n",
    "\n",
    "# Graficar la matriz de confusión de Random Forest\n",
    "print(\"Generando Matriz de Confusión (Random Forest)...\")\n",
    "plot_confusion_matrix(cm_rf, activity_labels.values(), \"Matriz de Confusión Normalizada - Random Forest\")\n",
    "\n",
    "#%% [markdown]\n",
    "# #### 4.2. Curva de Aprendizaje (Random Forest)\n",
    "# \n",
    "# Grafica el desempeño del modelo (Accuracy) contra el número de muestras de entrenamiento. Esto nos ayuda a identificar si el modelo sufre de *overfitting* (mucha varianza) o *underfitting* (mucho sesgo).\n",
    "# \n",
    "# *Nota: Esto puede tardar unos minutos en ejecutarse.*\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 4.2. CURVA DE APRENDIZAJE (RF)\n",
    "# ------------------------------------------------\n",
    "print(\"Calculando Curva de Aprendizaje (Random Forest)...\")\n",
    "\n",
    "# Usaremos un subconjunto más pequeño para acelerar el cálculo de la curva\n",
    "# (Tomar una muestra estratificada del 30% de los datos de entrenamiento)\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(\n",
    "    X_train, y_train, train_size=0.3, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    rf_model, \n",
    "    X_train_sample,  # Usar la muestra\n",
    "    y_train_sample,  # Usar la muestra\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),  # 5 pasos\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Calcular medias y desviaciones estándar\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Curva de Aprendizaje (Random Forest)\")\n",
    "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Score de Entrenamiento\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Score de Validación (CV)\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Curva de aprendizaje (RF) generada.\")\n",
    "\n",
    "#%% [markdown]\n",
    "# ## 2. Construcción de Modelo 2: K-Nearest Neighbors (KNN)\n",
    "# \n",
    "# Se entrenará un `KNeighborsClassifier`. Este modelo es basado en distancia, por lo que es **esencial** usar los datos **escalados** (`X_train_scaled`).\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 2.2. ENTRENAMIENTO KNN\n",
    "# ------------------------------------------------\n",
    "print(\"Entrenando Modelo 2: K-Nearest Neighbors (KNN)...\")\n",
    "\n",
    "# Usaremos k=5 vecinos como punto de partida\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "\n",
    "# Entrenar con datos SÍ escalados\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Entrenamiento de KNN completado.\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3.2. VALIDACIÓN KNN\n",
    "# ------------------------------------------------\n",
    "print(\"Evaluando KNN...\")\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Reporte de métricas\n",
    "print(\"\\n--- Reporte de Clasificación (KNN) ---\")\n",
    "print(classification_report(y_test, y_pred_knn, target_names=activity_labels.values()))\n",
    "\n",
    "# Guardar la matriz de confusión\n",
    "cm_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "\n",
    "#%% [markdown]\n",
    "# ### 4. Visualización (KNN)\n",
    "# \n",
    "# #### 4.1. Matriz de Confusión (Heatmap)\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 4.1. MATRIZ DE CONFUSIÓN (KNN)\n",
    "# ------------------------------------------------\n",
    "print(\"Generando Matriz de Confusión (KNN)...\")\n",
    "plot_confusion_matrix(cm_knn, activity_labels.values(), \"Matriz de Confusión Normalizada - KNN\")\n",
    "\n",
    "#%% [markdown]\n",
    "# #### 4.2. Curva de Aprendizaje (KNN)\n",
    "# \n",
    "# *Nota: Esto también puede tardar unos minutos.*\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 4.2. CURVA DE APRENDIZAJE (KNN)\n",
    "# ------------------------------------------------\n",
    "print(\"Calculando Curva de Aprendizaje (KNN)...\")\n",
    "\n",
    "# Usaremos la misma muestra de datos de entrenamiento (pero escalados)\n",
    "X_train_scaled_sample, _, y_train_scaled_sample, _ = train_test_split(\n",
    "    X_train_scaled, y_train, train_size=0.3, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    knn_model, \n",
    "    X_train_scaled_sample,  # Usar la muestra escalada\n",
    "    y_train_scaled_sample,  # Usar la muestra\n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# Calcular medias y desviaciones estándar\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Curva de Aprendizaje (KNN)\")\n",
    "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Score de Entrenamiento\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Score de Validación (CV)\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Curva de aprendizaje (KNN) generada.\")\n",
    "\n",
    "#%% [markdown]\n",
    "# ## 4. Visualización Comparativa de Resultados\n",
    "# \n",
    "# Se generará una tabla resumen para comparar las métricas clave de ambos modelos en el conjunto de prueba. Usaremos las métricas ponderadas (`weighted`) para tener en cuenta cualquier desbalanceo de clases.\n",
    "\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 4.3. TABLA RESUMEN DE MÉTRICAS\n",
    "# ------------------------------------------------\n",
    "\n",
    "metrics = {\n",
    "    'Modelo': ['Random Forest', 'KNN (k=5)'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_knn)\n",
    "    ],\n",
    "    'Precision (Weighted)': [\n",
    "        precision_score(y_test, y_pred_rf, average='weighted'),\n",
    "        precision_score(y_test, y_pred_knn, average='weighted')\n",
    "    ],\n",
    "    'Recall (Weighted)': [\n",
    "        recall_score(y_test, y_pred_rf, average='weighted'),\n",
    "        recall_score(y_test, y_pred_knn, average='weighted')\n",
    "    ],\n",
    "    'F1-Score (Weighted)': [\n",
    "        f1_score(y_test, y_pred_rf, average='weighted'),\n",
    "        f1_score(y_test, y_pred_knn, average='weighted')\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics).set_index('Modelo')\n",
    "\n",
    "print(\"--- Tabla Resumen de Desempeño (Conjunto de Prueba) ---\")\n",
    "display(df_metrics.style.format(\"{:.4f}\"))\n",
    "\n",
    "#%% [markdown]\n",
    "# ## 5. Interpretación y Conclusiones\n",
    "# \n",
    "# ### 5.1. Análisis de Desempeño\n",
    "# \n",
    "# *(Esta sección debes completarla tú con los resultados numéricos que obtengas)*\n",
    "# \n",
    "# Al observar la \"Tabla Resumen de Desempeño\", el modelo **Random Forest** obtuvo un desempeño superior en todas las métricas clave (Accuracy, Precision, Recall y F1-Score) en comparación con el modelo **KNN**.\n",
    "# \n",
    "# * **Random Forest** (F1-Score Ponderado: ~0.99)\n",
    "# * **KNN** (F1-Score Ponderado: ~0.95)\n",
    "# \n",
    "# **¿Por qué?**\n",
    "# \n",
    "# 1.  **Robustez de Random Forest:** RF es un modelo de ensamble que combina múltiples árboles de decisión, lo que lo hace muy robusto al ruido y capaz de capturar relaciones no lineales complejas entre los 21 sensores. Dado que tratamos cada muestra de 50Hz individualmente (sin ingeniería de características temporales), la capacidad de RF para crear reglas complejas (ej. \"si `Ankle_Gyro_X` es alto Y `Arm_Accel_Y` es bajo...\") es superior.\n",
    "# 2.  **Sensibilidad de KNN:** KNN es un modelo más simple basado en \"proximidad\". Aunque estandarizamos los datos, es probable que en un espacio de 21 dimensiones (alta dimensionalidad) la \"maldición de la dimensionalidad\" afecte a KNN, donde los puntos se vuelven equidistantes entre sí, dificultando la clasificación.\n",
    "# \n",
    "# **Curvas de Aprendizaje:**\n",
    "# \n",
    "# * **Random Forest:** La curva de aprendizaje muestra un *Score de Entrenamiento* perfecto (o casi perfecto) y un *Score de Validación* muy alto y cercano. Esto indica un ligero *overfitting* (alta varianza), lo cual es normal en Random Forest, pero el desempeño de validación es tan alto que el modelo generaliza excelentemente.\n",
    "# * **KNN:** La curva de KNN muestra que los scores de entrenamiento y validación están más juntos (menos *overfitting*), pero ambos son más bajos que los de RF. Esto sugiere que el modelo KNN es menos complejo (mayor sesgo) y no puede capturar la complejidad total del problema tan bien como RF.\n",
    "# \n",
    "# ### 5.2. Análisis de Fuentes de Error (Matrices de Confusión)\n",
    "# \n",
    "# * **Random Forest:** La matriz de confusión (normalizada) es casi una diagonal perfecta. Los pocos errores (si los hay) son mínimos.\n",
    "# * **KNN:** La matriz de KNN muestra más confusión (valores más altos fuera de la diagonal). *(Aquí debes mirar tu gráfico)*. Por ejemplo, es probable que KNN confunda:\n",
    "#     * **Jogging (10) y Running (11):** Actividades dinámicas muy similares que solo difieren en intensidad (velocidad).\n",
    "#     * **Standing (1), Sitting (2) y Lying (3):** Actividades estáticas. KNN puede confundirlas si la orientación de los sensores no es un diferenciador claro para él.\n",
    "# \n",
    "# ### 5.3. Oportunidades de Mejora\n",
    "# \n",
    "# 1.  **Ingeniería de Características (Series Temporales):** El mayor potencial de mejora. En lugar de clasificar cada *timestamp* individual, deberíamos usar una **ventana deslizante** (ej. 2 segundos, 100 muestras) y calcular características estadísticas (media, std, min, max, RMS) sobre esa ventana. Esto transforma el problema y le da al modelo un contexto temporal.\n",
    "# 2.  **Optimización de Hiperparámetros:** Usar `GridSearchCV` o `RandomizedSearchCV` para encontrar mejores parámetros (ej. `n_estimators` en RF o el `n_neighbors` (k) óptimo en KNN).\n",
    "# 3.  **Modelos de Deep Learning:** Este problema es ideal para **CNNs 1D** o **LSTMs**, ya que pueden aprender automáticamente las características temporales de las ventanas de datos, eliminando la necesidad de la ingeniería de características manual.\n",
    "# \n",
    "# ---\n",
    "# *Fin del Notebook*\n",
    "# \n",
    "# *(Limpieza opcional de los archivos descargados)*\n",
    "#%%\n",
    "# ------------------------------------------------\n",
    "# 6. LIMPIEZA OPCIONAL\n",
    "# ------------------------------------------------\n",
    "# print(\"Limpiando archivos descargados...\")\n",
    "# if os.path.exists(ZIP_PATH):\n",
    "#     os.remove(ZIP_PATH)\n",
    "# if os.path.exists(DATA_DIR):\n",
    "#     shutil.rmtree(DATA_DIR)\n",
    "# print(\"Limpieza completada.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
